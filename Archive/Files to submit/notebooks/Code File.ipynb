{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a23d50-d22b-44c4-9903-7fd93bd5a8c9",
   "metadata": {},
   "source": [
    "# **Assignment Report and Code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e49794-e0da-4c7d-a603-3056a644a8fc",
   "metadata": {},
   "source": [
    "### **Requirements met by this report**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be72c3c5-a283-46e6-b515-a8512b62ae3f",
   "metadata": {},
   "source": [
    "This assignment met the minimal/basic requirements. It also included Version Control using GitHub / Git. \n",
    "The version control file is in the folder ' git '\n",
    "\n",
    "### **Part 1 Refine the dataset**\n",
    "The requirements were to 'Develop a procedure to check that the data match expected format, remove duplicates, and perform further refinement. This procedure should ensure that:\n",
    "\n",
    "**1.** the values of variables are of the expected format (numbers, strings, etc.);\n",
    "\n",
    "**2.** the values of variables are admissible (e.g. are within a given range or are from the list of admissible values); in case of any inconsistencies and/or duplicates found, produce new file with refined data to be used in the subsequent analysis;'\n",
    "##### **Outcome:** These parts of the assignment were completed below.\n",
    "\n",
    "**3.** This step must be automated to the point when it can be run with a single shell command to call an executable Python script specifying necessary argument(s);\n",
    "##### **Outcome:** These steps can be run with the command:  python .\\main.py  This references a python file '../code/main.py'. As per the assignment requirements, this code is separated into a different file. However, the notes about the note are still in this report. \n",
    "\n",
    "**4.** the refinement process should be documented (e.g. using comments in the code) in case one may need to modify and re-run it (although it’s not necessary to repeat it each time while re-running the analysis),\n",
    "##### **Outcome:** Comments are visible throughout the code in Jupyter. Some comments also print when the command: python .\\main.py is used. This helps to explain what the code is doing and why.\n",
    "\n",
    "### **Part 2 Perform the descriptive analysis of the dataset**\n",
    "**1.** determine the total number of records in the dataset;\n",
    "\n",
    "**2.** determine the type of each variable in the dataset;\n",
    "\n",
    "**3.** for each variable except “Record_Number” and “Region”, find all different values that it takes, and the number of occurrences for each value,\n",
    "\n",
    "**4.** build a bar chart for the number of records for each age group;\n",
    "\n",
    "**5.** build a bar chart for the number of records for each occupation\n",
    "\n",
    "##### **Outcome:** These parts of the assignment were completed below.\n",
    "\n",
    "**6.** provide the Jupyter notebook to re-run the analysis, starting from refined data.\n",
    "##### **Outcome:** This is the notebook to re-run the analysis\n",
    "\n",
    "**7.** Important! For both basic and additional requirements, you need to ensure that the output provides textual interpretations for values of the variables from Teaching_File_Variable_List.xlsx instead of their alphanumeric codes.\n",
    "##### **Outcome:** These parts of the assignment were completed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc362b0e-8ae4-444d-8b73-c591a950b52c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Scotland_teaching_file_1PCT.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##importing panda and reading the file \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/Scotland_teaching_file_1PCT.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/Scotland_teaching_file_1PCT.csv'"
     ]
    }
   ],
   "source": [
    "##importing panda and reading the file \n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/Scotland_teaching_file_1PCT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35616918-deb2-4c89-b888-67a44a6d932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get list of column names\n",
    "get_col = list(pd.read_csv(\"../data/Scotland_teaching_file_1PCT.csv\",nrows=1).columns)\n",
    "#print(get_col)\n",
    "unique_values = {col: df[col].unique() for col in get_col}\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c8c27-062a-450c-a6ff-b4aa6d330cc1",
   "metadata": {},
   "source": [
    "### Based on this result, here is the output put onto separate lines to be more legible:\n",
    "You can see the data type and that many are objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3446566-f78a-44aa-a78f-5e81d22b78db",
   "metadata": {},
   "source": [
    "#### Outcome: Type of data and unique values in the dataset are now visible\n",
    "The completes the requirement to:\n",
    "* Determine the type of each variable in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088b548-1aa5-4071-b97e-73a15cc1cee5",
   "metadata": {},
   "source": [
    "## Refining Data Continued \n",
    "### Checking if values of variables are admissible and expected format\n",
    "#### From this part of the assignment guidelines: \n",
    "\n",
    "    develop a procedure to check that the data match expected format, remove duplicates, and perform further refinement. This procedure should ensure that:\n",
    "\n",
    "        1. the values of variables are of the expected format (numbers, strings, etc.);\n",
    "\n",
    "        2. the values of variables are admissible (e.g. are within a given range or are from the list of admissible values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eddf3d-a3ec-465f-afea-863a46096e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#importing panda to use on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd4997-bece-4c25-80c9-bb6f9de346b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## imported numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360add9-bf76-497d-9b37-0c48f60a6f9c",
   "metadata": {},
   "source": [
    "### Converting data to an array so it can be analysed using numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d773691e-ef7c-4259-ba73-b71d7a46ce09",
   "metadata": {},
   "source": [
    "#### Expected format of data\n",
    "Added manually based on the file 'Teaching_File_Variable_List' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e43af-cb01-4ffa-8f37-7888cf3acaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Record_Number_EF = np.array(list(range(1, 63389)))\n",
    "Region_EF = np.array(['S92000003'])\n",
    "RESIDENCE_TYPE_EF = np.array(['C', 'P'])\n",
    "Family_Composition_EF = np.array(['0', '1', '2', '3', '4', '5', 'X'])\n",
    "sex_EF = np.array([1, 2])\n",
    "age_EF = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "Marital_Status_EF = np.array([1, 2, 3, 4, 5])\n",
    "student_EF = np.array([1, 2])\n",
    "Country_Of_Birth_EF = np.array([1, 2])\n",
    "health_EF = np.array([1, 2, 3, 4, 5])\n",
    "Ethnic_Group_EF = np.array([1, 2, 4, 3, 5, 6])\n",
    "religion_EF = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "Economic_Activity_EF = np.array(['1', '2', '3', '4', '5', '6', '7', '8', '9', 'X'])\n",
    "Occupation_EF = np.array(['1', '2', '3', '4', '5', '6', '7', '8', '9', 'X'])\n",
    "industry_EF = np.array(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', 'X'])\n",
    "Hours_Worked_Per_Week_EF = np.array(['1', '2', '3', '4', 'X'])\n",
    "Approximate_Social_Grade_EF = np.array(['1', '2', '3', '4', 'X'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fccf05-fe62-414e-943c-a9d70420bddd",
   "metadata": {},
   "source": [
    "#### Real data\n",
    "Taken from output of unique values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e05a15-9593-494e-adb5-18c7dd9318bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Record_Number_RD = np.array(list(range(1, 63389)))\n",
    "Region_RD = np.array(['S92000003'])\n",
    "RESIDENCE_TYPE_RD = np.array(['P', 'C'])\n",
    "Family_Composition_RD = np.array(['1', '0', '4', '2', '5', '3', 'X'])\n",
    "sex_RD = np.array([1, 2])\n",
    "age_RD = np.array([4, 3, 6, 5, 1, 2, 7, 8])\n",
    "Marital_Status_RD = np.array([2, 1, 4, 3, 5])\n",
    "student_RD = np.array([2, 1])\n",
    "Country_Of_Birth_RD = np.array([2, 1])\n",
    "health_RD = np.array([2, 3, 1, 4, 5])\n",
    "Ethnic_Group_RD = np.array([1, 2, 4, 3, 6, 5])\n",
    "religion_RD = np.array([5, 1, 2, 9, 6, 8, 4, 7, 3])\n",
    "Economic_Activity_RD = np.array(['1', 'X', '5', '6', '9', '4', '2', '7', '3', '8'])\n",
    "Occupation_RD = np.array(['5', '1', '4', '2', '3', '9', 'X', '8', '6', '7'])\n",
    "industry_RD = np.array(['5', '8', '11', '9', 'X', '2', '4', '6', '7', '10', '3', '12', '13', '1'])\n",
    "Hours_Worked_Per_Week_RD = np.array(['4', '3', '2', 'X', '1'])\n",
    "Approximate_Social_Grade_RD = np.array(['3', '2', '4', 'X', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad647f79-623f-49c5-894e-4090046d65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code compares the expected format of the data to the real data recieved\n",
    "\n",
    "print('Values from dataset that do not match the expected format based on the file Teaching_File_Variable_List. Empty square brackets mean the data is the correct format and values')\n",
    "print('Record_Number:')\n",
    "print(np.setdiff1d(Record_Number_EF, Record_Number_RD)) \n",
    "print('Region:')\n",
    "print(np.setdiff1d(Region_EF, Region_RD))\n",
    "print('RESIDENCE_TYPE:')\n",
    "print(np.setdiff1d(RESIDENCE_TYPE_EF, RESIDENCE_TYPE_RD))\n",
    "print('Family_Composition_TYPE:')\n",
    "print(np.setdiff1d(Family_Composition_EF, Family_Composition_RD))\n",
    "print('sex_TYPE:')\n",
    "print(np.setdiff1d(sex_EF, sex_RD))\n",
    "print('age_TYPE:')\n",
    "print(np.setdiff1d(age_EF, age_RD))\n",
    "print('Marital_Status_TYPE:')\n",
    "print(np.setdiff1d(Marital_Status_EF, Marital_Status_RD))\n",
    "print('student:')\n",
    "print(np.setdiff1d(student_EF, student_RD))\n",
    "print('Country_Of_Birth:')\n",
    "print(np.setdiff1d(Country_Of_Birth_EF, Country_Of_Birth_RD))\n",
    "print('health:')\n",
    "print(np.setdiff1d(health_EF, health_RD))\n",
    "print('Ethnic_Group:')\n",
    "print(np.setdiff1d(Ethnic_Group_EF, Ethnic_Group_RD))\n",
    "print('religion:')\n",
    "print(np.setdiff1d(religion_EF, religion_RD))\n",
    "print('Economic_Activity:')\n",
    "print(np.setdiff1d(Economic_Activity_EF, Economic_Activity_RD))\n",
    "print('Occupation:')\n",
    "print(np.setdiff1d(Occupation_EF, Occupation_RD))\n",
    "print('industry:')\n",
    "print(np.setdiff1d(industry_EF, industry_RD))\n",
    "print('Hours_Worked_Per_Week:')\n",
    "print(np.setdiff1d(Hours_Worked_Per_Week_EF, Hours_Worked_Per_Week_RD))\n",
    "print('Approximate_Social_Grade:')\n",
    "print(np.setdiff1d(Approximate_Social_Grade_EF, Approximate_Social_Grade_RD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d9efbd-9508-4f79-87d4-608d54b5bdbc",
   "metadata": {},
   "source": [
    "#### Outcome: No unexpected values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dfdacf-ea84-4df4-9046-78c5082dd85b",
   "metadata": {},
   "source": [
    "## Remove Duplicates to New File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5943d94-3dca-4d5e-a240-389e40749c48",
   "metadata": {},
   "source": [
    "Column Record_Number not included in analysis, as it is a unique number given to each record, so it would not show duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b8c1a-c9d9-4ede-a2c2-548fb11c757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Scotland_teaching_file_1PCT.csv\")\n",
    "\n",
    "#Moving data without duplicates to a new file and naming i\n",
    "input_file = \"../data/Scotland_teaching_file_1PCT.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "output_file = \"../data/Scotland_teaching_file_1PCT_DUPLICATES_REMOVED.csv\" \n",
    "#From now on the new duplicates file will be used instead\n",
    "\n",
    "columns = [\"Region\", \"RESIDENCE_TYPE\", \"Family_Composition\", \"sex\", \"age\", \\\n",
    "           \"Marital_Status\", \"student\", \"Country_Of_Birth\", \"health\", \"Ethnic_Group\", \\\n",
    "           \"religion\", \"Economic_Activity\", \"Occupation\", \"industry\", \\\n",
    "           \"Hours_Worked_Per_Week\", \"Approximate_Social_Grade\"]\n",
    "\n",
    "deduplicated_data = df.drop_duplicates(subset=columns, keep=\"first\")\n",
    "\n",
    "dd = pd.DataFrame(deduplicated_data)\n",
    "dd.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397a02f-86d7-4484-930e-39149ec3d84a",
   "metadata": {},
   "source": [
    "## Descriptive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ebb5a-3127-4579-8267-8ee3519f019c",
   "metadata": {},
   "source": [
    "Determine the total number of records in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171735d3-491c-48d0-8b46-3747f891ed76",
   "metadata": {},
   "source": [
    "### Total number of records in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4bf37-22a4-49ba-a468-646f31997fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing number of rows\n",
    "rows = len(df.axes[0])\n",
    " \n",
    "# Computing number of columns\n",
    "cols = len(df.axes[1])\n",
    " \n",
    "print(\"Number of Rows: \", rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4193cf-c62f-49d1-b899-3ade1c316c52",
   "metadata": {},
   "source": [
    "### Total number of records in refined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79e3d7-26f8-44d3-9aa0-b8c09d5a5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the new file\n",
    "df = pd.read_csv('../data/Scotland_teaching_file_1PCT_DUPLICATES_REMOVED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0217da2-b760-4e15-8c48-2de5c91547a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing number of rows\n",
    "rows = len(df.axes[0])\n",
    " \n",
    "# Computing number of columns\n",
    "cols = len(df.axes[1])\n",
    " \n",
    "print(\"Number of Rows: \", rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6321fd-bca2-4219-8b06-13dfd10a57c1",
   "metadata": {},
   "source": [
    "#### Find all different values that it takes, and the number of occurrences for each value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb05ef-0001-411b-bf5b-0da598d82207",
   "metadata": {},
   "source": [
    "All different values already determined above "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0c203-b030-44e4-af6f-b1c2466e7f5f",
   "metadata": {},
   "source": [
    "### For each variable except “Record_Number” and “Region”\n",
    "\n",
    "a) find all different values that it takes\n",
    "b) the number of occurrences for each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f1f8d-6118-413b-ba00-261b417e3891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all different values that it takes\n",
    "#Read in the new file with no duplicates\n",
    "df = pd.read_csv('../data/Scotland_teaching_file_1PCT_DUPLICATES_REMOVED.csv')\n",
    "\n",
    "##Get list of column names\n",
    "col3 = 'RESIDENCE_TYPE'\n",
    "col4 = 'Family_Composition'\n",
    "col5 = 'sex'\n",
    "col6 = 'age'\n",
    "col7 = 'Marital_Status'\n",
    "col8 = 'student'\n",
    "col9 = 'Country_Of_Birth'\n",
    "col10 = 'health'\n",
    "col11 = 'Ethnic_Group'\n",
    "col12 = 'religion'\n",
    "col13 = 'Economic_Activity'\n",
    "col14 = 'Occupation'\n",
    "col15 = 'industry'\n",
    "col16 = 'Hours_Worked_Per_Week'\n",
    "col17 = 'Approximate_Social_Grade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67baeae0-1b8a-4b6d-a55d-da96d796d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code prints the unique values for each column, excluding the headings. It also prints the data type.\n",
    "unique_values = {col: df[col].unique() for col in [col3 ,\tcol4 ,\tcol5,\tcol6,\tcol7,\tcol8,\tcol9,\tcol10,\tcol11,\tcol12,\tcol13,\tcol14,\tcol15,\tcol16,\tcol17,\n",
    "]}\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f6f7f-bb4c-4775-921a-848ba2acd6e5",
   "metadata": {},
   "source": [
    "#### Converting data from codes to values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc22a2-d22b-4fac-b2a8-3bc095b61910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code replaces the 'data codes' originally sources from the data file Scotland_teaching_file_1PCT into the data from Teaching_File_Variable_List. \n",
    "\n",
    "file_path = '../data/Scotland_teaching_file_1PCT_DUPLICATES_REMOVED.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.replace({col3:{'C':'Resident in a Communal Establishment','P':'Not resident in a Communal Establishment'}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col4:{'0':'Not in a family',\n",
    "'1':'Married/same-sex civil partnership couple family',\n",
    "'2':'Cohabiting couple family',\n",
    "'3':'Lone parent family (male head)',\n",
    "'4':'Lone parent family (female lead)',\n",
    "'5':'Other related family',\n",
    "'X':'No code required (residents of a communal establishment)'\n",
    "}},inplace=True)\n",
    "           \n",
    "df.replace({col5:{1:'Male',2:'Female'}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col6:{1:'0 to 15',\n",
    "2:'16 to 24',\n",
    "3:'25 to 34',\n",
    "4:'35 to 44',\n",
    "5:'45 to 54',\n",
    "6:'55 to 64',\n",
    "7:'65 to 74',\n",
    "8:'75 and over'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col7:{1:'Single (Never married or never registered a same-sex civil partnership',\n",
    "2:'Married or in a same sex-civil partnership',\n",
    "3:'Separated, but still legally married or still legally in a same-sex civil partnership',\n",
    "4:'Divorced or formerly in a same-sex civil partnership which is now legally dissolved',\n",
    "5:'Widowed or surviving partner from a same-sex civil partnership'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col8:{1:'Yes',2:'No'}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col9:{1:'UK',\n",
    "2:'Non UK'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col10:{1:'Very good health',\n",
    "2:'Good health',\n",
    "3:'Fair health',\n",
    "4:'Bad health',\n",
    "5:'Very bad health',\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col11:{1:'White',\n",
    "2:'Mixed or multiple ethnic group',\n",
    "3:'Asian',\n",
    "4:'African',\n",
    "5:'Caribbean or black',\n",
    "6:'Other ethnic group'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col12:{1:'No religion',\n",
    "2:'Christian',\n",
    "3:'Buddhist',\n",
    "4:'Hindu',\n",
    "5:'Jewish',\n",
    "6:'Muslim',\n",
    "7:'Sikh',\n",
    "8:'Other religion',\n",
    "9:'Not stated'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col13:{'1':'Economically active: Employed',\n",
    "'2':'Economically active: Self-Employed',\n",
    "'3':'Economically active: Unemployed',\n",
    "'4':'Economically active: Full-time student',\n",
    "'5':'Economically inactive: Retired',\n",
    "'6':'Economically inactive: Student',\n",
    "'7':'Economically inactive: Looking after home or family',\n",
    "'8':'Economically inactive: Long-term sick or disabled',\n",
    "'9':'Economically inactive: Other',\n",
    "'X':'No code required (Aged under 16)'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col14:{'1':'Managers, Directors and Senior Officials',\n",
    "'2':'Professional Occupations',\n",
    "'3':'Associate Professional and Technical Occupations',\n",
    "'4':'Administrative and Secretarial Occupations',\n",
    "'5':'Skilled Trades Occupations',\n",
    "'6':'Caring, Leisure and Other Service Occupations',\n",
    "'7':'Sales and Customer Service Occupations',\n",
    "'8':'Process, Plant and Machine Operatives',\n",
    "'9':'Elementary Occupations',\n",
    "'X':'No code required (People aged under 16 and people who have never worked)'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col15:{'1':'Agriculture, forestry and fishing',\n",
    "'2':'Mining and quarrying; Manufacturing; Electricity, gas, steam and air conditioning system; Water supply',\n",
    "'3':'Construction',\n",
    "'4':'Wholesale and retail trade; Repair of motor vehicles and motorcycles',\n",
    "'5':'Accommodation and food service activities',\n",
    "'6':'Transport and storage; Information and communication',\n",
    "'7':'Financial and insurance activities',\n",
    "'8':'Real estate activities; Professional scientific and technical activities; Administrative and support service activities',\n",
    "'9':'Public administration and defence',\n",
    "'10':'Education',\n",
    "'11':'Human health and social work activities',\n",
    "'12':'Arts; entertainment and recreation',\n",
    "'13':'Other',\n",
    "'X':'No code required (People aged under 16 and people who have never worked)'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col16:{'1':'Part-time: 15 or less hours worked',\n",
    "'2':'Part-time: 16 to 30 hours worked',\n",
    "'3':'Full-time: 31 to 48 hours worked',\n",
    "'4':'Full-time 49 or more hours worked',\n",
    "'X':'No code required (People aged under 16 and people not working)'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "df.replace({col17:{'1':'AB',\n",
    "'2':'C1',\n",
    "'3':'C2',\n",
    "'4':'DE',\n",
    "'X':'No code required ( People aged under 16 and people resident in communal establishments)'\n",
    "}},\n",
    "           inplace=True)\n",
    "\n",
    "           \n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887f402-12c8-4272-8f4a-d9dac080a8e3",
   "metadata": {},
   "source": [
    "### Count the number of occurrences for each value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8229e8-8502-4053-87d7-49147c51641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Using the new file without duplicates\n",
    "\n",
    "# Count the occurrences of each value in the specified column\n",
    "value_counts3 = df[col3].value_counts()\n",
    "value_counts4 = df[col4].value_counts()\n",
    "value_counts5 = df[col5].value_counts()\n",
    "value_counts6 = df[col6].value_counts()\n",
    "value_counts7 = df[col7].value_counts()\n",
    "value_counts8 = df[col8].value_counts()\n",
    "value_counts9 = df[col9].value_counts()\n",
    "value_counts10 = df[col10].value_counts()\n",
    "value_counts11 = df['Ethnic_Group'].value_counts()\n",
    "value_counts12 = df['religion'].value_counts()\n",
    "value_counts13 = df['Economic_Activity'].value_counts()\n",
    "value_counts14 = df['Occupation'].value_counts()\n",
    "value_counts15 = df['industry'].value_counts()\n",
    "value_counts16 = df['Hours_Worked_Per_Week'].value_counts()\n",
    "value_counts17 = df['Approximate_Social_Grade'].value_counts()\n",
    "\n",
    "print(value_counts3,value_counts4,value_counts5,value_counts6,value_counts7,value_counts8,value_counts9,value_counts10,value_counts11,value_counts12,value_counts13,value_counts14,value_counts15,value_counts16,value_counts17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e800955-b037-4400-9080-9c0c4b9cf6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc7c262e-6663-42f4-8fc7-a1ade7da56ce",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9c241-f5c0-4c47-8d4c-3eaaaf0b6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "#importing matlab to use for visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92edd141-dd1b-4ad3-bf1d-ca10fb284bae",
   "metadata": {},
   "source": [
    "### Bar chart of age according to labels on data in Teaching_File_Variable_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde99517-2235-495a-8764-0a9e3e584263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataset\n",
    "data = {'0 to 15':558,\n",
    "'16 to 24':4927,\n",
    "'25 to 34':6298,\n",
    "'35 to 44':6719,\n",
    "'45 to 54':6724,\n",
    "'55 to 64':5895,\n",
    "'65 to 74':3550,\n",
    "'75 and over':2842}\n",
    "\n",
    "age_groups = list(data.keys())\n",
    "values = list(data.values())\n",
    "  \n",
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(age_groups, values, color ='purple', \n",
    "        width = 0.5)\n",
    " \n",
    "plt.xlabel(\"Age in Years\")\n",
    "plt.ylabel(\"Number of Participants\")\n",
    "plt.title(\"Age Group Distribution of Census Participants\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebd1cd4-2736-490b-b935-23f3c32d4c1a",
   "metadata": {},
   "source": [
    "## Bar chart for the number of records for each occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71738e74-5d57-4cd2-93ee-d3f0c19488f2",
   "metadata": {},
   "source": [
    "#### Bar chart of occupation according to labels on data in Scotland_teaching_file_1PCT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f22553-3f9f-4a80-af0f-e8b0e3aafba3",
   "metadata": {},
   "source": [
    "# creating the dataset\n",
    "data = {'Managers, Directors and Senior Officials':5662,\n",
    "'Professional Occupations':4602,\n",
    "'Associate Professional and Technical Occupations':4316,\n",
    "'Administrative and Secretarial Occupations':4097,\n",
    "'Skilled Trades Occupations':3818,\n",
    "'Caring, Leisure and Other Service Occupations':3363,\n",
    "'Sales and Customer Service Occupations':3351,\n",
    "'Process, Plant and Machine Operatives':3052,\n",
    "'Elementary Occupations':2858,\n",
    "'People aged under 16 and people who have never worked':2394,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0441da-e45b-489c-8436-4411d90e8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataset\n",
    "data = {'1':5662,\n",
    "'2':4602,\n",
    "'3':4316,\n",
    "'4':4097,\n",
    "'5':3818,\n",
    "'6':3363,\n",
    "'7':3351,\n",
    "'8':3052,\n",
    "'9':2858,\n",
    "'X':2394,\n",
    "}\n",
    "\n",
    "datalabel = {'Bar Chart Key:','\t1. Managers, Directors and Senior Officials\t','\t2. Professional Occupations\t','\t3. Associate Professional and Technical Occupations\t','\t4. Administrative and Secretarial Occupations\t','\t5. Skilled Trades Occupations\t','\t6. Caring, Leisure and Other Service Occupations\t','\t7. Sales and Customer Service Occupations\t','\t8. Process, Plant and Machine Operatives\t','\t9. Elementary Occupations\t','\tX. People aged under 16 and people who have never worked\t'}\n",
    "\n",
    "age_groups = list(data.keys())\n",
    "values = list(data.values())\n",
    "  \n",
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(age_groups, values, color ='purple', \n",
    "        width = 0.5)\n",
    " \n",
    "plt.xlabel(\"Occupation Groups\")\n",
    "plt.ylabel(\"Number of Participants\")\n",
    "plt.title(\"Occupation Groups Distribution of Census Participants\")\n",
    "plt.show()\n",
    "\n",
    "#The text was too long to be legible for the barchart using the method I used for the previous chart. So, I installed and imported Plotly.Express version 0.4.0\n",
    "#It's an interactive, open-source Python plotting library\n",
    "import plotly.express as px\n",
    "#I included x but changed the phrasing from the original file to remove 'No Code Required' so the bar chart was easier to read\n",
    "\n",
    "plt.legend(datalabel)\n",
    "\n",
    "print('Bar Chart Key:')\n",
    "print('\t1. Managers, Directors and Senior Officials\t')\n",
    "print('\t2. Professional Occupations\t')\n",
    "print('\t3. Associate Professional and Technical Occupations\t')\n",
    "print('\t4. Administrative and Secretarial Occupations\t')\n",
    "print('\t5. Skilled Trades Occupations\t')\n",
    "print('\t6. Caring, Leisure and Other Service Occupations\t')\n",
    "print('\t7. Sales and Customer Service Occupations\t')\n",
    "print('\t8. Process, Plant and Machine Operatives\t')\n",
    "print('\t9. Elementary Occupations\t')\n",
    "print('\tX. People aged under 16 and people who have never worked\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822120f-dc0e-417e-9759-f3c44f66bb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765852ef-7831-4b1c-847b-5cf316eba97b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
